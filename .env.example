# Gibsey Mycelial Network Environment Configuration
# Rename this to .env and add your API keys

# ===========================================
# DATABASE CONFIGURATION
# ===========================================
# Mock database (development)
DATABASE_URL=mock://localhost

# Production Cassandra (when ready)
# DATABASE_URL=cassandra://localhost:9042/gibsey
# CASSANDRA_KEYSPACE=gibsey
# CASSANDRA_USERNAME=your-username
# CASSANDRA_PASSWORD=your-password

# ===========================================
# LLM PROVIDER CONFIGURATION (PHASE 3)
# ===========================================

# --- OLLAMA (Local LLM Server) ---
# Start Ollama: `ollama serve`
# Pull model: `ollama pull llama3.1:8b`
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=2000

# --- OPENAI (Cloud Fallback) ---
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# --- CLAUDE/ANTHROPIC (Cloud Fallback) ---
ANTHROPIC_API_KEY=your-anthropic-api-key-here
CLAUDE_MODEL=claude-3-haiku-20240307
CLAUDE_TEMPERATURE=0.7
CLAUDE_MAX_TOKENS=2000

# ===========================================
# VECTOR EMBEDDINGS
# ===========================================
# Use local sentence transformers (default)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Or use OpenAI embeddings (requires OPENAI_API_KEY)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-ada-002

# ===========================================
# LEGACY DSPY CONFIGURATION
# ===========================================
# Optional: Choose model (gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo)
DSPY_MODEL=gpt-4

# Optional: Temperature for responses (0.0-1.0)
DSPY_TEMPERATURE=0.8

# Optional: MLflow tracking URI (if using experiment tracking)
MLFLOW_TRACKING_URI=mlruns

# ===========================================
# DEVELOPMENT & TESTING
# ===========================================
# Set to 'true' to enable debug logging
DEBUG=false

# Set to 'true' to use mock LLM responses (for development)
USE_MOCK_LLM=false