# QDPI Backend Runbook

Commands to run the minimal QDPI→DSPy backend system.

## Prerequisites

- Python 3.12+ with virtual environment
- Docker (for Cassandra, optional)
- Node.js (for frontend, handled by Gemini)

## Phase 1: Backend Setup (Complete ✅)

### 1. Schema Initialization
```bash
# Initialize Cassandra QDPI schema
python backend/scripts/init_qdpi_schema.py
```

### 2. Canon Ingestion
```bash
# Ingest 710 canonical pages (dry run first)
python scripts/ingest_canon.py --dry-run

# Actual ingestion (requires Cassandra)
python scripts/ingest_canon.py --from corpus
```

### 3. API Server
```bash
# Start FastAPI server
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 4. Test Pipeline
```bash
# Test symbol execution endpoint
curl -X POST "http://localhost:8000/api/v1/pipeline/run/symbol/0x00" \
  -H "Content-Type: application/json" \
  -d '{"user_intent":"continue"}'

# List all symbols
curl "http://localhost:8000/api/v1/pipeline/symbols"

# Health check
curl "http://localhost:8000/api/v1/pipeline/health"
```

### 5. Run Tests
```bash
# QDPI core tests
python -m pytest tests/test_qdpi_basic.py -v

# API integration tests  
python -m pytest tests/test_pipeline_api.py -v

# All tests
python -m pytest tests/ -v
```

## Phase 2: Kafka Setup (Optional)

### 1. Start Kafka
```bash
# Using docker-compose (if available)
docker-compose -f docker-compose.kafka.yml up -d

# Create topics manually if needed
kafka-topics --create --topic gibsey.generate.page.request
kafka-topics --create --topic gibsey.generate.page.done
kafka-topics --create --topic gibsey.ui.symbol
```

### 2. Enable Kafka in Backend
```bash
# Set environment variable
export KAFKA_ENABLED=true

# Or edit backend/.env
echo "KAFKA_ENABLED=true" >> backend/.env
```

### 3. Test Kafka Integration
```bash
python backend/test_kafka_integration.py
```

## Phase 3: Database Setup (When Available)

### 1. Start Cassandra
```bash
# Using docker-compose
docker-compose -f docker-compose.cassandra.yml up -d cassandra

# Wait for startup (check logs)
docker-compose -f docker-compose.cassandra.yml logs -f cassandra
```

### 2. Initialize Schema
```bash
# Run schema initialization
python backend/scripts/init_qdpi_schema.py

# Verify tables created
cqlsh -e "USE gibsey; DESCRIBE TABLES;"
```

### 3. Ingest Canon
```bash
# Load all 710 pages with NEXT edges
python scripts/ingest_canon.py

# Verify ingestion
cqlsh -e "USE gibsey; SELECT COUNT(*) FROM pages;"
```

## Troubleshooting

### Common Issues

**Import Errors:**
```bash
# Install missing dependencies
pip install dspy-ai aiokafka sentencepiece
```

**API Server Won't Start:**
```bash
# Check for dependency conflicts
pip install --upgrade fastapi uvicorn

# Run basic test
python backend/test_pipeline_api.py
```

**Database Connection:**
```bash
# Check Cassandra status
docker ps | grep cassandra

# Test connection
cqlsh localhost 9042
```

### Environment Variables

Required in `backend/.env`:
```env
CASSANDRA_HOSTS=localhost:9042
CASSANDRA_KEYSPACE=gibsey
KAFKA_ENABLED=false
KAFKA_BROKERS=localhost:9092
EMBEDDING_DIM=384
```

## File Locations

### Core Implementation
- `backend/qdpi/` - QDPI core library
- `backend/app/api/pipeline.py` - FastAPI endpoints
- `backend/workers/kafka_io.py` - Event streaming

### Scripts
- `scripts/cassandra_qdpi_init.cql` - Database schema
- `scripts/ingest_canon.py` - Canon loader
- `backend/scripts/init_qdpi_schema.py` - Schema initializer

### Tests
- `tests/test_qdpi_basic.py` - Symbol encoding tests
- `tests/test_pipeline_api.py` - API integration tests

## API Endpoints

Base URL: `http://localhost:8000`

- `POST /api/v1/pipeline/run/symbol/{code}` - Execute QDPI pipeline
- `GET /api/v1/pipeline/symbols` - List all symbols
- `POST /api/v1/pipeline/branch/{page_id}` - Create branch
- `GET /api/v1/pipeline/health` - Health check
- `GET /api/docs` - Interactive API documentation

## Next Steps

1. **Codex CLI**: Generate glyph manifest from `qdpi-256-glyphs/`
2. **Gemini CLI**: Build 256-grid UI consuming these APIs
3. **Integration**: Connect all three components for end-to-end flow

---

*Generated by Claude Code on 2025-08-18*