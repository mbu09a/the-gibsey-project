# Local AI Hosting - Ollama / vLLM instances